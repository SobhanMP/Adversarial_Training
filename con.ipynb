{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict, defaultdict\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from src import *\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "!mkdir -p figures\n",
    "!mkdir -p snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "# PGK\n",
    "ϵ = 8 / 256\n",
    "ϵ_s = 2 / 256\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "val_K = 10\n",
    "retrain = 10\n",
    "EPOCHS = 300\n",
    "TEST_EVERY = 30\n",
    "batch_size = 128\n",
    "pre_train = False\n",
    "\n",
    "small = False\n",
    "training_with_replay_Ks = [1, 4, 10, 30]\n",
    "free_Ks = [1, 2, 4, 10, 20]\n",
    "\n",
    "    \n",
    "PGD_Ks = [1, 2, 7]\n",
    "\n",
    "\n",
    "attack_names = ['FSM', 'PGD-20', 'PGD-100', 'CW-100']\n",
    "attacks = [\n",
    "     *[PGD(K, ϵ, 2.5 * ϵ/K) for K in [1, 20, 100]],\n",
    "     CW(100, 1e4, ϵ, 2.5 * ϵ/ 100)]\n",
    "    \n",
    "    \n",
    "if small:\n",
    "    EPOCHS = 5\n",
    "    TEST_EVERY = 5\n",
    "    training_with_replay_Ks = [1, 5]\n",
    "    free_Ks = [1, 5]\n",
    "    attack_names = ['FSM', 'PGD-2', 'CW-2']\n",
    "    attacks = [\n",
    "         *[PGD(K, ϵ, 2.5 * ϵ/K) for K in [1, 2]],\n",
    "         CW(2, 1e4, ϵ, 2.5 * ϵ/ 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(EPOCHS == K * int(EPOCHS / K) for K in training_with_replay_Ks)\n",
    "assert all(EPOCHS == K * int(EPOCHS / K) for K in free_Ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR INPUT\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomCrop(32, padding=4),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True, transform=transform)\n",
    "if small:\n",
    "    trainset = torch.utils.data.Subset(trainset, range(batch_size))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, num_workers=4, \n",
    "        pin_memory=True, drop_last=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "\n",
    "if small:\n",
    "    testset = torch.utils.data.Subset(testset, range(batch_size))\n",
    "    \n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size * 4,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = StandardScalerLayer(lambda: map(lambda x: x[0], trainloader))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def build_model(ϵ=ϵ):\n",
    "    model = WideResNet(28, 10, 10, 0.1)\n",
    "    adv = AdversarialForFree(ϵ, 0, 1)\n",
    "    if ϵ not in [0, False]:\n",
    "        l = [('adv', adv)]\n",
    "    else:\n",
    "        l = []\n",
    "    l.extend([\n",
    "        ('normalizer', norm),\n",
    "        ('resnet', model)])\n",
    "    return nn.Sequential(OrderedDict(l)).cuda()\n",
    "\n",
    "imgsize = images.size()[1:]\n",
    "imgsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "\n",
      " training with 1 replays\n",
      "train \t 1: 1.5880 40.0% 71.2s\n",
      "train \t 2: 1.1595 57.8% 71.2s\n",
      "train \t 3: 0.9540 65.9% 71.5s\n",
      "train \t 4: 0.8208 71.3% 71.4s\n",
      "train \t 5: 0.7153 74.9% 71.3s\n",
      "train \t 6: 0.6392 77.7% 71.2s\n",
      "train \t 7: 0.5713 80.4% 71.1s\n",
      "train \t 8: 0.5228 81.9% 71.0s\n",
      "train \t 9: 0.4808 83.5% 70.9s\n",
      "train \t 10: 0.4478 84.7% 70.8s\n",
      "train \t 11: 0.4202 85.6% 70.8s\n"
     ]
    }
   ],
   "source": [
    "#standard training with replay logs\n",
    "srl = defaultdict(lambda : defaultdict(lambda : []))\n",
    "\n",
    "for K in training_with_replay_Ks:\n",
    "    print(f'\\n\\n\\n\\n\\n------------------------\\n\\n\\n\\n training with {K} replays')\n",
    "\n",
    "    model = build_model(False)\n",
    "    optimizer = optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "        \n",
    "    for epoch in range(int(EPOCHS / K)): # loop over the dataset multiple times\n",
    "            \n",
    "        logs = train_with_replay(K, model, trainloader, optimizer, epoch)\n",
    "        srl[K]['train'].append(logs)\n",
    "        if (epoch * K + K) % TEST_EVERY == 0:\n",
    "            # valdiation loss\n",
    "            logs = run_val(model, testloader, epoch)\n",
    "            srl[K]['test'].append(logs)\n",
    "            run_attacks(srl[K], attacks, \n",
    "                        attack_names, model, testloader, epoch)\n",
    "    print('Finished Training')\n",
    "    torch.save(model.state_dict(), f\"wresnet-cifar-10-normal-{K}.pch\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "with open('snapshots/srl.pickle', 'wb') as fd:\n",
    "    pickle.dump(holder_to_dict(srl), fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2, ax1) = plt.subplots(ncols=2, figsize=(15,7))\n",
    "\n",
    "y = [srl[K][\"test\"][-1].acc * 100 for K in training_with_replay_Ks]\n",
    "bars = ax1.bar([f'$m={K}$' for K in training_with_replay_Ks], y)\n",
    "for (i, bar) in zip(y, bars):\n",
    "    t = ax1.text(bar.get_x() + bar.get_width() /2 - 0.07 , bar.get_height() + 0.10, f'{i:0.1f}%')\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.set_xlabel('number of replay steps $m$')\n",
    "ax1.set_ylabel('validation accuracy ($\\%$)')\n",
    "\n",
    "ax2.set_ylabel('validation loss (KL)')\n",
    "y = [srl[K][\"test\"][-1].loss for K in training_with_replay_Ks]\n",
    "bars = ax2.bar([f'$m={K}$' for K in training_with_replay_Ks], y)\n",
    "for (i, bar) in zip(y, bars):\n",
    "    t = ax2.text(bar.get_x() + bar.get_width() /2 - 0.07 , bar.get_height() + 0.10, f'{i:0.1f}')\n",
    "def savefig(fig, name, f=['svg', 'pdf', 'png']):\n",
    "    for e in f:\n",
    "        fig.savefig('figures/' + name + '.' + e)\n",
    "savefig(fig, 'cost_of_replay')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_logs = defaultdict(lambda : defaultdict(lambda :[]))\n",
    "\n",
    "for K in free_Ks:\n",
    "    model = build_model()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(int(EPOCHS / K)):  # loop over the dataset multiple times\n",
    "        logs = train_with_replay(K, model, trainloader, optimizer, epoch,\n",
    "                                after_func=lambda model: model.adv.step())\n",
    "        free_logs[K]['train'].append(logs)\n",
    "        \n",
    "        if (epoch * K + K) % TEST_EVERY == 0:\n",
    "\n",
    "            logs = run_val(model, testloader, epoch)\n",
    "            free_logs[K]['test'].append(logs)\n",
    "\n",
    "            # adv loss\n",
    "            run_attacks(free_logs[K], attacks, attack_names, model, testloader, epoch)\n",
    "    \n",
    "\n",
    "    print('Finished Training')\n",
    "    torch.save(model.state_dict(), f\"snapshots/wresnet-cifar-10-free-{K}.pch\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "with open('snapshots/free_logs.pickle', 'wb') as fd:\n",
    "    pickle.dump(holder_to_dict(free_logs), fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pgd_logs = defaultdict(lambda : defaultdict(lambda : []))\n",
    "\n",
    "for K in PGD_Ks:\n",
    "    model = build_model(False)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    attack = PGD(K, ϵ, 2.5 * ϵ / K)\n",
    "    \n",
    "    for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        logs = train_with_replay(1, \n",
    "             model, \n",
    "             trainloader, \n",
    "             optimizer,\n",
    "             epoch,\n",
    "             input_func=lambda inputs, labels: attack(model, inputs, labels))\n",
    "        pgd_logs[K]['train'].append(logs)\n",
    "        \n",
    "        if (epoch + 1) % TEST_EVERY == 0:\n",
    "    \n",
    "            logs = run_val(model, testloader, epoch)\n",
    "            pgd_logs[K]['test'].append(logs)\n",
    "            run_attacks(pgd_logs[K], attacks, \n",
    "                        attack_names, model, testloader, epoch)\n",
    "\n",
    "    print('Finished Training')\n",
    "    torch.save(model.state_dict(), f\"snapshots/wresnet-cifar-10-pgk-{K}.pch\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "with open('snapshots/pgd_logs.pickle', 'wb') as fd:\n",
    "    pickle.dump(holder_to_dict(pgd_logs), fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = lambda x: f'$${x * 100:.2f}\\%$$'\n",
    "d = {}\n",
    "d['Training'] = ['Natural', \n",
    "         *[f'Free $m={K}$' for K in free_Ks],\n",
    "         *[f'{K}-PGD' for K in PGD_Ks]]\n",
    "\n",
    "\n",
    "x = [srl[1]['test'][-1].acc,\n",
    "         *[free_logs[K]['test'][-1].acc for K in free_Ks],\n",
    "         *[pgd_logs[K]['test'][-1].acc for K in PGD_Ks]]\n",
    "\n",
    "d['Natural Images'] = list(map(fmt, x))\n",
    "            \n",
    "for name in attack_names:\n",
    "    n = f'adv_test/{name}'\n",
    "    \n",
    "    x = [srl[1][n][-1].acc]\n",
    "    \n",
    "    for K in free_Ks:\n",
    "        x.append(free_logs[K][n][-1].acc)\n",
    "    \n",
    "    for K in PGD_Ks:\n",
    "        x.append(pgd_logs[K][n][-1].acc)\n",
    "    d[name] = list(map(fmt, x))\n",
    "        \n",
    "tt = lambda x: sum(i.time for i in x)\n",
    "fmt = lambda x: f'$${math.ceil(x / 60)}$$'\n",
    "x = [srl[1]['train'],\n",
    "    *[free_logs[K]['train'] for K in free_Ks],\n",
    "    *[pgd_logs[K]['train'] for K in PGD_Ks]]\n",
    "\n",
    "d['Training Time(M)'] = list(map(lambda x: fmt(tt(x)), x))\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('figures/grid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_latex('figures/grid.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
